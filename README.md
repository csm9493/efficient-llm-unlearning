# Towards Robust and Cost-Efficient Knowledge Unlearning for Large Language Models
Official Repository for Towards Robust and Cost-Efficient Knowledge Unlearning for Large Language Models (ICLR 2025, [Paper Link](https://openreview.net/forum?id=1ExfUpmIW4))

!(Illustration of IHL and FILA)[assets/method_illustration.pdf]

This repository is largely derived from the TOFU dataset [repo](https://github.com/locuslab/tofu)

### 0. Setup Environment


### 1. Full finetune to obtain base models
```
bash run_finetune.sh
```

### 2. Unlearn forget set from base models (with LoRA)

### 3. Evaluate unlearned model

### 4. Aggregate evaluation results
